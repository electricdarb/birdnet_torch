{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch \n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "#from openvino.inference_engine import IECore\n",
    "import timm\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.load__analysis('analysisinit', 'mobilenetv3_hpsearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (3, 224, 224)\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "def torch_to_onnx(model, path, batch_size, input_shape):\n",
    "    dummy_input = torch.randn(batch_size, *input_shape, requires_grad=True)\n",
    "\n",
    "    torch.onnx.export(model,           # model being run\n",
    "                  dummy_input,                         # model input (or a tuple for multiple inputs)\n",
    "                  path,   # where to save the model (can be a file or file-like object)\n",
    "                  export_params = True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version = 10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding = True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes = {'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                 'output' : {0 : 'batch_size'}})\n",
    "    \n",
    "    print(f\"model saved to {path}\")\n",
    "\n",
    "def load_onnx_model(path):\n",
    "    model = onnx.load(path)\n",
    "    onnx.checker.check_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MobileNetV3' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1508/3329660421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtorch_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmobilenet_v3_large\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtorch_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\torch_p37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m-> 1186\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MobileNetV3' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "torch_model = models.mobilenet_v3_large()\n",
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = 'convnext_tiny.onnx'\n",
    "\n",
    "torch_to_onnx(torch_model, path, batch_size, INPUT_SHAPE)\n",
    "onnx_model = load_onnx_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "ort_session = ort.InferenceSession(path)\n",
    "\n",
    "# define model input x to test onx vs torch\n",
    "inputs = torch.randn(batch_size, *INPUT_SHAPE)\n",
    "\n",
    "torch_out = torch_model(inputs)\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(inputs)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MYRIAD': <class '__main__.Versions'>}\n",
      "MYRIAD\n",
      "MKLDNNPlugin version ......... 2.1\n",
      "Build ........... 2021.4.0-3839-cd81789d294-releases/2021/4\n"
     ]
    }
   ],
   "source": [
    "ie = IECore()\n",
    "device = 'MYRIAD'\n",
    "model = ie.read_network(model = path)\n",
    "versions = ie.get_versions(device)\n",
    "print(versions)\n",
    "\n",
    "print(f\"{device}\")\n",
    "print(f\"MKLDNNPlugin version ......... {versions[device].major}.{versions[device].minor}\")\n",
    "print(f\"Build ........... {versions[device].build_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "for input_key in model.input_info:\n",
    "     print(model.input_info[input_key].input_data.shape)\n",
    "\n",
    "for input_key in model.input_info:\n",
    "    input_name = input_key\n",
    "    model.input_info[input_key].precision = 'FP32'\n",
    "    break\n",
    "assert (len(model.input_info.keys()) == 1 or len(model.input_info.keys()) == 2), \"Sample supports topologies only with 1 or 2 inputs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python \"C:\\\\Program Files (x86)\\\\Intel\\\\openvino_2021\\\\deployment_tools\\\\model_optimizer\\\\mo.py\" --input_model \"C:\\\\Users\\\\14135\\\\Desktop\\\\birdnet_torch\\\\convnext_tiny.onnx\" --output_dir \"C:\\\\Users\\\\14135\\\\Desktop\\\\birdnet_torch\\\\\" --input_shape (1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ie.read_network(model = 'convnext_tiny.xml', weights = 'convnext_tiny.bin')\n",
    "\n",
    "exec_net = ie.load_network(network = net, device_name = device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "208af9daca7244bc307c856959856af182492b20a8a60620ec04a79d87aa7eb9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch_p37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
